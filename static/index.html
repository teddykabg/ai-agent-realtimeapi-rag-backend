<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Agent with RAG</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter+Tight:wght@400;500;600&display=swap" rel="stylesheet">
    <style>
        :root {
            /* Primary colors */
            --color-accent: #2356FF;
            
            /* Secondary colors */
            --color-secondary-100: #EBF4FF;
            --color-secondary-200: #2DB2FF;
            --color-secondary-300: #1D36B6;
            
            /* Neutral colors */
            --color-neutral-100: #FFFFFF;
            --color-neutral-200: #F1F4FF;
            --color-neutral-300: #CBD2EA;
            --color-neutral-400: #B3BAD3;
            --color-neutral-500: #8791AD;
            --color-neutral-600: #515B79;
            --color-neutral-700: #00143F;
            --color-neutral-800: #001035;
            
            /* Typography - Display sizes (font-size) */
            --font-size-display-11: 56px;
            --font-size-display-10: 48px;
            --font-size-display-9: 40px;
            --font-size-display-8: 36px;
            --font-size-display-7: 32px;
            --font-size-display-6: 28px;
            --font-size-display-5: 24px;
            --font-size-display-4: 20px;
            --font-size-display-3: 18px;
            --font-size-display-2: 16px;
            --font-size-display-1: 14px;
            
            /* Typography - Display sizes (line-height) */
            --line-height-display-11: 62px;
            --line-height-display-10: 53px;
            --line-height-display-9: 46px;
            --line-height-display-8: 45px;
            --line-height-display-7: 40px;
            --line-height-display-6: 35px;
            --line-height-display-5: 30px;
            --line-height-display-4: 25px;
            --line-height-display-3: 23px;
            --line-height-display-2: 20px;
            --line-height-display-1: 18px;
            
            /* Typography - Paragraph styles */
            --font-size-paragraph-large: 14px;
            --line-height-paragraph-large: 21px;
            --font-size-paragraph-default: 16px;
            --line-height-paragraph-default: 24px;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        html {
            scroll-behavior: smooth;
        }

        body {
            font-family: 'Inter Tight', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            background: #FAFAFA;
            min-height: 100vh;
            padding: 0;
            color: var(--color-neutral-700);
        }

        .container {
            max-width: 1400px;
            margin: 0 auto;
            background: var(--color-neutral-100);
            min-height: 100vh;
        }

        .header {
            background: var(--color-neutral-100);
            border-bottom: 1px solid #E5E7EB;
            color: var(--color-neutral-800);
            padding: 32px 48px;
            text-align: left;
        }

        .header h1 {
            font-size: var(--font-size-display-6);
            line-height: var(--line-height-display-6);
            font-weight: 600;
            margin-bottom: 4px;
            color: var(--color-neutral-800);
            letter-spacing: -0.02em;
        }

        .header p {
            font-size: var(--font-size-paragraph-default);
            line-height: var(--line-height-paragraph-default);
            color: var(--color-neutral-500);
            font-weight: 400;
        }

        .content {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 24px;
            padding: 48px;
        }

        @media (max-width: 768px) {
            .content {
                grid-template-columns: 1fr;
                padding: 24px;
                gap: 24px;
            }
            
            .header {
                padding: 24px;
            }
            
            .header h1 {
                font-size: var(--font-size-display-7);
                line-height: var(--line-height-display-7);
            }
        }

        .panel {
            background: var(--color-neutral-100);
            border-radius: 8px;
            padding: 32px;
            border: 1px solid #E5E7EB;
            box-shadow: 0 1px 2px rgba(0, 0, 0, 0.04);
        }

        .panel h2 {
            color: var(--color-neutral-800);
            margin-bottom: 24px;
            font-size: var(--font-size-display-4);
            line-height: var(--line-height-display-4);
            font-weight: 600;
            letter-spacing: -0.01em;
        }

        .upload-section {
            margin-bottom: 24px;
        }

        .upload-form {
            display: flex;
            flex-direction: column;
            gap: 16px;
        }

        .file-input-wrapper {
            position: relative;
            overflow: hidden;
            display: inline-block;
            width: 100%;
        }

        .file-input-wrapper input[type=file] {
            position: absolute;
            left: -9999px;
        }

        .file-input-label {
            display: inline-block;
            width: 100%;
            padding: 10px 20px;
            background: var(--color-neutral-100);
            color: var(--color-neutral-700);
            border: 1px solid #D1D5DB;
            border-radius: 6px;
            cursor: pointer;
            transition: all 200ms ease;
            text-align: center;
            font-size: var(--font-size-paragraph-default);
            line-height: var(--line-height-paragraph-default);
            font-weight: 500;
        }

        .file-input-label:hover {
            background: #F9FAFB;
            border-color: var(--color-accent);
            color: var(--color-accent);
        }

        .file-input-label:active {
            background: #F3F4F6;
        }

        .upload-btn {
            padding: 10px 20px;
            background: var(--color-neutral-800);
            color: var(--color-neutral-100);
            border: none;
            border-radius: 6px;
            cursor: pointer;
            font-size: var(--font-size-paragraph-default);
            line-height: var(--line-height-paragraph-default);
            font-weight: 500;
            transition: all 200ms ease;
            font-family: 'Inter Tight', sans-serif;
        }

        .upload-btn:hover:not(:disabled) {
            background: var(--color-neutral-700);
        }

        .upload-btn:active:not(:disabled) {
            background: var(--color-neutral-800);
        }

        .upload-btn:disabled {
            background: #E5E7EB;
            color: #9CA3AF;
            cursor: not-allowed;
        }

        .status {
            padding: 10px 14px;
            border-radius: 6px;
            margin-top: 12px;
            font-size: var(--font-size-paragraph-large);
            line-height: var(--line-height-paragraph-large);
        }

        .status.success {
            background: #ECFDF5;
            color: #065F46;
            border: 1px solid #A7F3D0;
        }

        .status.error {
            background: #FEF2F2;
            color: #991B1B;
            border: 1px solid #FECACA;
        }

        .status.info {
            background: #F0F9FF;
            color: #0C4A6E;
            border: 1px solid #BAE6FD;
        }

        .voice-section {
            display: flex;
            flex-direction: column;
            gap: 24px;
        }

        .connection-status {
            padding: 8px 12px;
            border-radius: 6px;
            text-align: center;
            font-weight: 500;
            font-size: var(--font-size-paragraph-large);
            line-height: var(--line-height-paragraph-large);
            border: 1px solid;
        }

        .connection-status.connected {
            background: #ECFDF5;
            color: #065F46;
            border-color: #A7F3D0;
        }

        .connection-status.disconnected {
            background: #FEF2F2;
            color: #991B1B;
            border-color: #FECACA;
        }

        .connection-status.connecting {
            background: #F0F9FF;
            color: #0C4A6E;
            border-color: #BAE6FD;
        }

        .voice-controls {
            display: flex;
            gap: 16px;
            justify-content: center;
            align-items: center;
        }

        .record-btn {
            width: 64px;
            height: 64px;
            border-radius: 50%;
            border: 1px solid #E5E7EB;
            cursor: pointer;
            font-size: 24px;
            font-weight: 500;
            transition: all 200ms ease;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
            display: flex;
            align-items: center;
            justify-content: center;
            background: var(--color-neutral-100);
        }

        .record-btn.recording {
            background: #DC2626;
            color: var(--color-neutral-100);
            border-color: #DC2626;
            animation: pulse 1.5s infinite;
            box-shadow: 0 0 0 4px rgba(220, 38, 38, 0.1);
        }

        .record-btn:not(.recording) {
            background: var(--color-neutral-800);
            color: var(--color-neutral-100);
            border-color: var(--color-neutral-800);
        }

        .record-btn:hover:not(:disabled) {
            transform: scale(1.05);
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.15);
        }

        .record-btn:active:not(:disabled) {
            transform: scale(0.98);
        }

        .record-btn:disabled {
            background: #F3F4F6;
            color: #9CA3AF;
            border-color: #E5E7EB;
            cursor: not-allowed;
            transform: none;
            box-shadow: none;
        }

        @keyframes pulse {
            0%, 100% { 
                transform: scale(1);
                box-shadow: 0 0 0 4px rgba(220, 38, 38, 0.1);
            }
            50% { 
                transform: scale(1.05);
                box-shadow: 0 0 0 8px rgba(220, 38, 38, 0.15);
            }
        }

        .transcript {
            background: #FAFAFA;
            border: 1px solid #E5E7EB;
            border-radius: 8px;
            padding: 20px;
            min-height: 300px;
            max-height: 400px;
            overflow-y: auto;
            font-family: 'Inter Tight', sans-serif;
            font-size: var(--font-size-paragraph-default);
            line-height: var(--line-height-paragraph-default);
        }

        .message {
            margin-bottom: 12px;
            padding: 12px 16px;
            border-radius: 6px;
        }

        .message.user {
            background: var(--color-neutral-100);
            border-left: 2px solid var(--color-accent);
        }

        .message.assistant {
            background: var(--color-neutral-100);
            border-left: 2px solid #6B7280;
        }

        .message.system {
            background: #F9FAFB;
            border-left: 2px solid #9CA3AF;
        }

        .message-label {
            font-weight: 600;
            margin-bottom: 6px;
            color: var(--color-neutral-800);
            font-size: var(--font-size-display-1);
            line-height: var(--line-height-display-1);
            text-transform: uppercase;
            letter-spacing: 0.05em;
        }

        .message div:last-child {
            color: var(--color-neutral-700);
            font-size: var(--font-size-paragraph-default);
            line-height: var(--line-height-paragraph-default);
        }

        .hidden {
            display: none;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>Voice Agent with RAG</h1>
            <p>Upload documents and chat with voice</p>
        </div>

        <div class="content">
            <!-- Upload Panel -->
            <div class="panel">
                <h2>Upload Documents</h2>
                <div class="upload-section">
                    <form id="uploadForm" class="upload-form">
                        <div class="file-input-wrapper">
                            <input type="file" id="fileInput" accept=".txt,.pdf,.md,.doc,.docx" multiple>
                            <label for="fileInput" class="file-input-label">
                                Choose Files
                            </label>
                        </div>
                        <div id="fileList"></div>
                        <button type="submit" class="upload-btn" id="uploadBtn">
                            Upload & Process
                        </button>
                        <div id="uploadStatus"></div>
                    </form>
                </div>
            </div>

            <!-- Voice Panel -->
            <div class="panel">
                <h2>Voice Chat</h2>
                <div class="voice-section">
                    <div id="connectionStatus" class="connection-status disconnected">
                        Disconnected
                    </div>
                    
                    <div class="voice-controls">
                        <button id="recordBtn" class="record-btn" disabled>
                            <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                                <path d="M12 1a3 3 0 0 0-3 3v8a3 3 0 0 0 6 0V4a3 3 0 0 0-3-3z"></path>
                                <path d="M19 10v2a7 7 0 0 1-14 0v-2"></path>
                                <line x1="12" y1="19" x2="12" y2="23"></line>
                                <line x1="8" y1="23" x2="16" y2="23"></line>
                            </svg>
                        </button>
                    </div>

                    <div class="transcript" id="transcript">
                        <div class="message info">
                            <div class="message-label">Info:</div>
                            <div>Connect to start chatting with voice</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <script>
        const API_BASE = window.location.origin;
        const WS_PROTOCOL = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
        const WS_URL = `${WS_PROTOCOL}//${window.location.host}/ws/realtime`;

        let ws = null;
        let isRecording = false;
        let mediaRecorder = null;
        let inputAudioContext = null;  // For microphone input
        let audioChunks = [];
        let sessionId = null;
        let processedTranscriptItems = new Set();  // Track processed transcript item_ids to prevent duplicates

        // Initialize
        document.addEventListener('DOMContentLoaded', () => {
            setupFileUpload();
            setupVoiceChat();
            connectWebSocket();
        });

        // File Upload
        function setupFileUpload() {
            const fileInput = document.getElementById('fileInput');
            const fileList = document.getElementById('fileList');
            const uploadForm = document.getElementById('uploadForm');
            const uploadBtn = document.getElementById('uploadBtn');
            const uploadStatus = document.getElementById('uploadStatus');

            fileInput.addEventListener('change', (e) => {
                const files = Array.from(e.target.files);
                if (files.length === 0) return;

                fileList.innerHTML = `<div class="status info">Selected ${files.length} file(s)</div>`;
            });

            uploadForm.addEventListener('submit', async (e) => {
                e.preventDefault();
                const files = fileInput.files;
                if (files.length === 0) {
                    showStatus(uploadStatus, 'Please select files to upload', 'error');
                    return;
                }

                uploadBtn.disabled = true;
                uploadBtn.textContent = 'Uploading...';

                const formData = new FormData();
                for (let file of files) {
                    formData.append('file', file);
                }

                try {
                    const response = await fetch(`${API_BASE}/upload`, {
                        method: 'POST',
                        body: formData
                    });

                    const result = await response.json();
                    if (response.ok) {
                        showStatus(uploadStatus, 
                            `Success! Processed ${result.chunks_processed} chunks`, 
                            'success'
                        );
                        fileInput.value = '';
                        fileList.innerHTML = '';
                    } else {
                        showStatus(uploadStatus, `Error: ${result.detail || 'Upload failed'}`, 'error');
                    }
                } catch (error) {
                    showStatus(uploadStatus, `Error: ${error.message}`, 'error');
                } finally {
                    uploadBtn.disabled = false;
                    uploadBtn.textContent = 'Upload & Process';
                }
            });
        }

        function showStatus(element, message, type) {
            element.innerHTML = `<div class="status ${type}">${message}</div>`;
            setTimeout(() => {
                element.innerHTML = '';
            }, 5000);
        }

        // Voice Chat
        function setupVoiceChat() {
            const recordBtn = document.getElementById('recordBtn');

            recordBtn.addEventListener('click', async () => {
                if (!isRecording) {
                    await startRecording();
                } else {
                    stopRecording();
                }
            });
        }

        async function connectWebSocket() {
            const statusEl = document.getElementById('connectionStatus');
            const recordBtn = document.getElementById('recordBtn');

            statusEl.textContent = 'Connecting...';
            statusEl.className = 'connection-status connecting';

            try {
                ws = new WebSocket(WS_URL);

                ws.onopen = () => {
                    statusEl.textContent = 'Connected';
                    statusEl.className = 'connection-status connected';
                    recordBtn.disabled = false;
                    addMessage('system', 'Connected to Realtime API');
                };

                ws.onmessage = (event) => {
                    const data = JSON.parse(event.data);
                    handleRealtimeEvent(data);
                };

                ws.onerror = (error) => {
                    console.error('WebSocket error:', error);
                    statusEl.textContent = 'Connection Error';
                    statusEl.className = 'connection-status disconnected';
                };

                ws.onclose = () => {
                    statusEl.textContent = 'Disconnected';
                    statusEl.className = 'connection-status disconnected';
                    recordBtn.disabled = true;
                    addMessage('system', 'Disconnected from server');
                    
                    // Reconnect after 3 seconds
                    setTimeout(connectWebSocket, 3000);
                };

            } catch (error) {
                console.error('Connection error:', error);
                statusEl.textContent = 'Failed to Connect';
                statusEl.className = 'connection-status disconnected';
            }
        }

        function handleRealtimeEvent(event) {
            console.log('Received event:', event.type, event);
            
            // Debug: Log all transcript-related events
            if (event.type && (event.type.includes('transcript') || event.type.includes('transcription'))) {
                console.log('[DEBUG] Transcript event details:', {
                    type: event.type,
                    delta: event.delta,
                    transcript: event.transcript,
                    text: event.text,
                    item_id: event.item_id,
                    fullEvent: event
                });
            }

            // Handle session events
            if (event.type === 'session.created' || event.type === 'session.updated') {
                sessionId = event.session?.id;
                addMessage('system', `Session ${sessionId ? 'created' : 'updated'}`);
            }

            // Handle audio output - use correct event type
            if (event.type === 'response.output_audio.delta') {
                // Check if this is a new audio item (like push-to-talk app)
                if (event.item_id && event.item_id !== lastAudioItemId) {
                    console.log(`New audio item started: ${event.item_id}`);
                    resetAudioQueue();
                    lastAudioItemId = event.item_id;
                }
                
                // Decode and play audio
                if (event.delta) {
                    playAudioChunk(event.delta);
                }
            }

            // Handle transcripts - check multiple event types
            if (event.type === 'response.output_audio_transcript.delta') {
                if (event.delta) {
                    appendTranscript('assistant', event.delta);
                }
            }

            // Also handle text output events (in case audio mode sends text)
            if (event.type === 'response.output_text.delta') {
                if (event.delta) {
                    appendTranscript('assistant', event.delta);
                }
            }

            // Handle user transcript delta events (real-time as user speaks)
            if (event.type === 'conversation.item.input_audio_transcription.delta') {
                console.log('[TRANSCRIPT] User transcript delta:', event.delta);
                if (event.delta) {
                    appendTranscript('user', event.delta);
                    // Mark that we're receiving delta events for this item
                    if (event.item_id) {
                        processedTranscriptItems.add(event.item_id);
                    }
                } else {
                    console.warn('[TRANSCRIPT] Delta event received but no delta field:', event);
                }
            }

            // Handle completed transcript events
            if (event.type === 'conversation.item.input_audio_transcription.completed') {
                const transcript = event.transcript || event.text;
                const itemId = event.item_id;
                console.log('[TRANSCRIPT] User transcript completed:', transcript, 'item_id:', itemId);
                
                // Skip if we've already processed this item_id
                if (itemId && processedTranscriptItems.has(itemId)) {
                    console.log('[TRANSCRIPT] Skipping duplicate completed event for item_id:', itemId);
                    return;
                }
                
                if (transcript) {
                    // Only add completed message if we haven't already shown it via delta events
                    const transcriptEl = document.getElementById('transcript');
                    const lastMessage = transcriptEl.lastElementChild;
                    const lastContent = lastMessage?.querySelector('div:last-child')?.textContent.trim();
                    if (!lastMessage || !lastMessage.classList.contains('user') || 
                        lastContent !== transcript.trim()) {
                        addMessage('user', transcript);
                    }
                    // Mark this item as processed
                    if (itemId) {
                        processedTranscriptItems.add(itemId);
                    }
                } else {
                    console.warn('[TRANSCRIPT] Completed event received but no transcript field:', event);
                }
            }

            // Handle errors
            if (event.type === 'error') {
                console.error('Realtime API error:', event.message);
                addMessage('system', `Error: ${event.message || 'Unknown error'}`);
            }
        }

        async function startRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        sampleRate: 24000,
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true
                    }
                });
                
                inputAudioContext = new (window.AudioContext || window.webkitAudioContext)({
                    sampleRate: 24000
                });

                const source = inputAudioContext.createMediaStreamSource(stream);
                const processor = inputAudioContext.createScriptProcessor(4096, 1, 1);

                audioChunks = [];
                isRecording = true;
                document.getElementById('recordBtn').classList.add('recording');
                document.getElementById('recordBtn').innerHTML = '<svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><rect x="6" y="6" width="12" height="12" rx="2"></rect></svg>';

                processor.onaudioprocess = (e) => {
                    if (!isRecording || !ws || ws.readyState !== WebSocket.OPEN) return;

                    const inputData = e.inputBuffer.getChannelData(0);
                    const pcm16 = new Int16Array(inputData.length);
                    
                    for (let i = 0; i < inputData.length; i++) {
                        pcm16[i] = Math.max(-32768, Math.min(32767, inputData[i] * 32768));
                    }

                    // Convert to base64
                    const bytes = new Uint8Array(pcm16.buffer);
                    let binary = '';
                    for (let i = 0; i < bytes.length; i++) {
                        binary += String.fromCharCode(bytes[i]);
                    }
                    const base64Audio = btoa(binary);

                    // Send audio chunk to OpenAI
                    ws.send(JSON.stringify({
                        type: 'input_audio_buffer.append',
                        audio: base64Audio
                    }));
                };

                source.connect(processor);
                processor.connect(inputAudioContext.destination);

                window.audioStream = stream;
                window.audioProcessor = processor;

            } catch (error) {
                console.error('Error starting recording:', error);
                alert('Error accessing microphone. Please check permissions.');
                isRecording = false;
                document.getElementById('recordBtn').classList.remove('recording');
                document.getElementById('recordBtn').innerHTML = '<svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M12 1a3 3 0 0 0-3 3v8a3 3 0 0 0 6 0V4a3 3 0 0 0-3-3z"></path><path d="M19 10v2a7 7 0 0 1-14 0v-2"></path><line x1="12" y1="19" x2="12" y2="23"></line><line x1="8" y1="23" x2="16" y2="23"></line></svg>';
            }
        }

        function stopRecording() {
            isRecording = false;
            document.getElementById('recordBtn').classList.remove('recording');
            document.getElementById('recordBtn').innerHTML = '<svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M12 1a3 3 0 0 0-3 3v8a3 3 0 0 0 6 0V4a3 3 0 0 0-3-3z"></path><path d="M19 10v2a7 7 0 0 1-14 0v-2"></path><line x1="12" y1="19" x2="12" y2="23"></line><line x1="8" y1="23" x2="16" y2="23"></line></svg>';

            if (window.audioProcessor) {
                window.audioProcessor.disconnect();
            }
            if (window.audioStream) {
                window.audioStream.getTracks().forEach(track => track.stop());
            }

            // With server_vad, we only need to commit - response is created automatically
            // But we can optionally create it with explicit audio output
            if (ws && ws.readyState === WebSocket.OPEN) {
                ws.send(JSON.stringify({
                    type: 'input_audio_buffer.commit'
                }));
                // Note: With server_vad, response is created automatically after commit
                // But we can explicitly request audio output
                ws.send(JSON.stringify({
                    type: 'response.create',
                    response: {
                        modalities: ["audio", "text"]
                    }
                }));
            }
        }

        // Audio playback queue - similar to AudioPlayerAsync from audio_util.py
        let audioQueue = [];
        let isPlaying = false;
        let outputAudioContext = null;  // For audio output/playback
        let lastAudioItemId = null;  // Track audio item IDs for queue management
        const SAMPLE_RATE = 24000;

        // Initialize audio context for playback
        function initAudioContext() {
            if (!outputAudioContext || outputAudioContext.state === 'closed') {
                outputAudioContext = new (window.AudioContext || window.webkitAudioContext)({
                    sampleRate: SAMPLE_RATE
                });
            }
            // Resume if suspended (browser autoplay policy)
            if (outputAudioContext.state === 'suspended') {
                outputAudioContext.resume();
            }
            return outputAudioContext;
        }

        function playAudioChunk(audioData) {
            try {
                // Decode base64 to binary
                const binaryString = atob(audioData);
                const bytes = new Uint8Array(binaryString.length);
                for (let i = 0; i < binaryString.length; i++) {
                    bytes[i] = binaryString.charCodeAt(i);
                }

                // Convert Int16 PCM to Float32 (same as audio_util.py approach)
                const pcm16 = new Int16Array(bytes.buffer);
                const float32 = new Float32Array(pcm16.length);
                for (let i = 0; i < pcm16.length; i++) {
                    float32[i] = pcm16[i] / 32768.0;
                }

                // Add to queue
                audioQueue.push(float32);
                console.log(`Audio chunk added: ${float32.length} samples (${(float32.length/SAMPLE_RATE*1000).toFixed(1)}ms), queue size: ${audioQueue.length}`);

                // Start playback if not already playing
                if (!isPlaying) {
                    playAudioQueue();
                }
            } catch (error) {
                console.error('Error processing audio chunk:', error);
            }
        }

        async function playAudioQueue() {
            if (audioQueue.length === 0) {
                isPlaying = false;
                return;
            }

            isPlaying = true;
            const ctx = initAudioContext();

            try {
                while (audioQueue.length > 0) {
                    const chunk = audioQueue.shift();
                    if (!chunk || chunk.length === 0) continue;

                    // Create audio buffer
                    const buffer = ctx.createBuffer(1, chunk.length, SAMPLE_RATE);
                    buffer.getChannelData(0).set(chunk);
                    
                    // Create and play source
                    const source = ctx.createBufferSource();
                    source.buffer = buffer;
                    source.connect(ctx.destination);
                    
                    // Play chunk
                    await new Promise((resolve, reject) => {
                        source.onended = resolve;
                        source.onerror = reject;
                        try {
                            source.start(0);
                        } catch (e) {
                            // May fail if already started
                            resolve();
                        }
                    });
                }
            } catch (error) {
                console.error('Error playing audio queue:', error);
            } finally {
                isPlaying = false;
            }
        }

        // Reset audio queue for new audio item (like reset_frame_count in audio_util.py)
        function resetAudioQueue() {
            audioQueue = [];
            console.log('Audio queue reset');
        }

        function addMessage(role, text) {
            const transcript = document.getElementById('transcript');
            const message = document.createElement('div');
            message.className = `message ${role}`;
            message.innerHTML = `
                <div class="message-label">${role === 'user' ? 'You' : role === 'assistant' ? 'Assistant' : 'System'}:</div>
                <div>${text}</div>
            `;
            transcript.appendChild(message);
            transcript.scrollTop = transcript.scrollHeight;
        }

        function appendTranscript(role, delta) {
            const transcript = document.getElementById('transcript');
            let lastMessage = transcript.lastElementChild;
            
            if (!lastMessage || !lastMessage.classList.contains('message') || 
                !lastMessage.classList.contains(role)) {
                lastMessage = document.createElement('div');
                lastMessage.className = `message ${role}`;
                lastMessage.innerHTML = `
                    <div class="message-label">${role === 'assistant' ? 'Assistant' : 'You'}:</div>
                    <div></div>
                `;
                transcript.appendChild(lastMessage);
            }

            const contentDiv = lastMessage.querySelector('div:last-child');
            contentDiv.textContent += delta;
            transcript.scrollTop = transcript.scrollHeight;
        }
    </script>
</body>
</html>

